---
---

@string{aps = {American Physical Society,}}

@article{bhattacharya_precision_2017,
	title = {Precision {Diagnosis} {Of} {Melanoma} {And} {Other} {Skin} {Lesions} {From} {Digital} {Images}},
	volume = {2017},
	copyright = {All rights reserved},
	issn = {2153-4063},
	abstract = {Melanoma will affect an estimated 73,000 new cases this year and result in 9,000 deaths, yet precise diagnosis remains a serious problem. Without early detection and preventative care, melanoma can quickly spread to become fatal (Stage IV 5-year survival rate is 20-10\%) from a once localized skin lesion (Stage IA 5- year survival rate is 97\%). There is no biomarker for melanoma in clinical use, and the current diagnostic criteria for skin lesions remains subjective and imprecise. Accurate diagnosis of melanoma relies on a histopathologic gold standard; thus, aggressive excision of melanocytic skin lesions has been the mainstay of treatment. It is estimated that 36 biopsies are performed for every melanoma confirmed by pathology among excised lesions. There is significant morbidity in misdiagnosing melanoma such as progression of the disease for a false negative prediction vs the risks of unnecessary surgery for a false positive prediction. Every year, poor diagnostic precision adds an estimated \$673 million in overall cost to manage the disease. Currently, manual dermatoscopic imaging is the standard of care in selecting atypical skin lesions for biopsy, and at best it achieves 90\% sensitivity but only 59\% specificity when performed by an expert dermatologist. Many computer vision (CV) algorithms perform better than dermatologists in classifying skin lesions although not significantly so in clinical practice. Meanwhile, open source deep learning (DL) techniques in CV have been gaining dominance since 2012 for image classification, and today DL can outperform humans in classifying millions of digital images with less than 5\% error rates. Moreover, DL algorithms are readily run on commoditized hardware and have a strong online community of developers supporting their rapid adoption. In this work, we performed a successful pilot study to show proof of concept to DL skin pathology from images. However, DL algorithms must be trained on very large labelled datasets of images to achieve high accuracy. Here, we begin to assemble a large imageset of skin lesions from the UCSF and the San Francisco Veterans Affairs Medical Center (VAMC) dermatology clinics that are well characterized by their underlying pathology, on which to train DL algorithms. If trained on sufficient data, we hypothesize that our approach will significantly outperform general dermatologists in predicting skin lesion pathology. We posit that our work will allow for precision diagnosis of melanoma from widely available digital photography, which may optimize the management of the disease by decreasing unnecessary office visits and the significant morbidity and cost of melanoma misdiagnosis.},
	language = {eng},
	journal = {AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science},
	author = {Bhattacharya, Abhishek and Young, Albert and Wong, Andrew and Stalling, Simone and Wei, Maria and Hadley, Dexter},
	year = {2017},
	pmid = {28815132},
	pmcid = {PMC5543387},
	pages = {220--226},
	pdf = {Bhattacharya_Precision.pdf}
}

@article{young_patient_2021,
	title = {Patient and general public attitudes towards clinical artificial intelligence: a mixed methods systematic review},
	volume = {3},
	copyright = {All rights reserved},
	issn = {2589-7500},
	shorttitle = {Patient and general public attitudes towards clinical artificial intelligence},
	url = {https://www.sciencedirect.com/science/article/pii/S2589750021001321},
	doi = {10.1016/S2589-7500(21)00132-1},
	abstract = {Artificial intelligence (AI) promises to change health care, with some studies showing proof of concept of a provider-level performance in various medical specialties. However, there are many barriers to implementing AI, including patient acceptance and understanding of AI. Patients’ attitudes toward AI are not well understood. We systematically reviewed the literature on patient and general public attitudes toward clinical AI (either hypothetical or realised), including quantitative, qualitative, and mixed methods original research articles. We searched biomedical and computational databases from Jan 1, 2000, to Sept 28, 2020, and screened 2590 articles, 23 of which met our inclusion criteria. Studies were heterogeneous regarding the study population, study design, and the field and type of AI under study. Six (26\%) studies assessed currently available or soon-to-be available AI tools, whereas 17 (74\%) assessed hypothetical or broadly defined AI. The quality of the methods of these studies was mixed, with a frequent issue of selection bias. Overall, patients and the general public conveyed positive attitudes toward AI but had many reservations and preferred human supervision. We summarise our findings in six themes: AI concept, AI acceptability, AI relationship with humans, AI development and implementation, AI strengths and benefits, and AI weaknesses and risks. We suggest guidance for future studies, with the goal of supporting the safe, equitable, and patient-centred implementation of clinical AI.},
	language = {en},
	number = {9},
	urldate = {2022-10-08},
	journal = {The Lancet Digital Health},
	author = {Young, Albert T and Amara, Dominic and Bhattacharya, Abhishek and Wei, Maria L},
	month = sep,
	year = {2021},
	pages = {e599--e611},
	pdf = {Young_Systematic_AI.pdf}
}

@article{jiang_rapid_2022,
	title = {Rapid {Automated} {Analysis} of {Skull} {Base} {Tumor} {Specimens} {Using} {Intraoperative} {Optical} {Imaging} and {Artificial} {Intelligence}},
	volume = {90},
	copyright = {All rights reserved},
	issn = {0148-396X},
	url = {https://journals.lww.com/neurosurgery/Fulltext/2022/06000/Rapid_Automated_Analysis_of_Skull_Base_Tumor.14.aspx?context=FeaturedArticles&collectionId=11},
	doi = {10.1227/neu.0000000000001929},
	abstract = {BACKGROUND: 
        Accurate specimen analysis of skull base tumors is essential for providing personalized surgical treatment strategies. Intraoperative specimen interpretation can be challenging because of the wide range of skull base pathologies and lack of intraoperative pathology resources.
        OBJECTIVE: 
        To develop an independent and parallel intraoperative workflow that can provide rapid and accurate skull base tumor specimen analysis using label-free optical imaging and artificial intelligence.
        METHODS: 
        We used a fiber laser–based, label-free, nonconsumptive, high-resolution microscopy method ({\textless}60 seconds per 1 × 1 mm2), called stimulated Raman histology (SRH), to image a consecutive, multicenter cohort of patients with skull base tumor. SRH images were then used to train a convolutional neural network model using 3 representation learning strategies: cross-entropy, self-supervised contrastive learning, and supervised contrastive learning. Our trained convolutional neural network models were tested on a held-out, multicenter SRH data set.
        RESULTS: 
        SRH was able to image the diagnostic features of both benign and malignant skull base tumors. Of the 3 representation learning strategies, supervised contrastive learning most effectively learned the distinctive and diagnostic SRH image features for each of the skull base tumor types. In our multicenter testing set, cross-entropy achieved an overall diagnostic accuracy of 91.5\%, self-supervised contrastive learning 83.9\%, and supervised contrastive learning 96.6\%. Our trained model was able to segment tumor-normal margins and detect regions of microscopic tumor infiltration in meningioma SRH images.
        CONCLUSION: 
        SRH with trained artificial intelligence models can provide rapid and accurate intraoperative analysis of skull base tumor specimens to inform surgical decision-making.},
	language = {en-US},
	number = {6},
	urldate = {2022-10-08},
	journal = {Neurosurgery},
	author = {Jiang, Cheng and Bhattacharya, Abhishek and Linzey, Joseph R. and Joshi, Rushikesh S. and Cha, Sung Jik and Srinivasan, Sudharsan and Alber, Daniel and Kondepudi, Akhil and Urias, Esteban and Pandian, Balaji and Al-Holou, Wajd N. and Sullivan, Stephen E. and Thompson, B. Gregory and Heth, Jason A. and Freudiger, Christian W. and Khalsa, Siri Sahib S. and Pacione, Donato R. and Golfinos, John G. and Camelo-Piragua, Sandra and Orringer, Daniel A. and Lee, Honglak and Hollon, Todd C.},
	month = jun,
	year = {2022},
	pages = {758--767},
	pdf = {Jiang_Skull.pdf}
}
